{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For importing converted final tsv into sqlite\n",
    "import os\n",
    "import csv\n",
    "csv.field_size_limit(100000000)\n",
    "import time\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('../db.sqlite3')\n",
    "conn.isolation_level=None\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"PRAGMA journal_mode=WAL\")\n",
    "directory_name = os.path.join(os.pardir, 'coreapi/dataset/imdb/')\n",
    "buffer_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = lambda val: val.strip() if val not in [\"\\\\N\", \"\"] else None\n",
    "namebasics = lambda i,row: (row[0], row[1])\n",
    "titleakas = lambda i,row: (i, row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[0])\n",
    "titlebasics = lambda i,row: (*row, None)\n",
    "titleprincipals = lambda i,row: (i, row[1], row[3], row[4], row[5], row[2], row[0])\n",
    "titlerating = lambda i,row: (i, row[1], row[2], row[0])\n",
    "titlelink = lambda i,row: (i, *row)\n",
    "\n",
    "writer_table   = \"coreapi_titlebasics_writers\" \n",
    "director_table = \"coreapi_titlebasics_directors\"\n",
    "crew_file = \"title_crew.tsv\"\n",
    "\n",
    "def flush_buffer(table_name, buffer, n_col):\n",
    "    q_m = (\"?, \"*n_col)[:-2]\n",
    "    sql= \"insert or replace into \" + table_name + \" values(\"+ q_m + \")\"\n",
    "    cur.executemany(sql, buffer)\n",
    "    buffer.clear()\n",
    "\n",
    "def insert_table(table_name, file_name, f, n_col, sep=\"\\t\"):\n",
    "    read_file = os.path.join(directory_name, file_name)\n",
    "    reader = csv.reader(open(read_file), delimiter=sep)\n",
    "    start_time = time.time()\n",
    "    col_s = len(next(reader))\n",
    "    try:\n",
    "        cur.execute(\"begin\")\n",
    "        buffer=[]\n",
    "        for idx, row in enumerate(reader,1):\n",
    "            if len(row) == col_s:\n",
    "                row = map(clean, row)\n",
    "                row = f(idx, row)\n",
    "                buffer.append(row)\n",
    "                if not idx%buffer_size:\n",
    "                    flush_buffer(table_name, buffer, n_col)\n",
    "                    print(\"\\rwritten\", f'{idx:,}', \"entries of \", table_name, end=\"\")\n",
    "\n",
    "        if len(buffer):\n",
    "            flush_buffer(table_name, buffer, n_col)\n",
    "\n",
    "        cur.execute(\"commit\")\n",
    "        print(\"\\nTotal time \", time.time()-start_time)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        cur.execute(\"rollback\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_crew():\n",
    "    start_time = time.time()\n",
    "    with open(read_file) as r:\n",
    "        reader = csv.reader(r, delimiter=\"\\t\")\n",
    "        column_names = next(reader)\n",
    "        ir=0\n",
    "        iw=0\n",
    "        writer_buffer=[]\n",
    "        director_biffer=[]\n",
    "        for cnt, row in enumerate(reader, 1):\n",
    "            tconst = is_valid(row[0])\n",
    "            directors = [clean(i) for i in row[1].split(',')]\n",
    "            directors = row[1].split(',')\n",
    "            writers = row[2].split(',')\n",
    "            for d in directors:\n",
    "                director_buffer.append(map(clean, [ir, tconst, d]))\n",
    "                ir+=1\n",
    "            for w in writers:\n",
    "                writer_buffer.append((map(clean, [ir, tconst, w])))\n",
    "                iw+=1\n",
    "            if not cnt%buffer_size:\n",
    "                flush_buffer(writer_table, writer_buffer, 3)\n",
    "                flush_buffer(director_table, director_buffer, 3)\n",
    "                print(\"written\", f'{iw:,}', \"writers \", f'{ir:,}', \"directors\", end=\"\\r\")\n",
    "\n",
    "    print(\"Converted \", table_name, \" in \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written 10,800,000 entries of  coreapi_titlebasics\n",
      "Total time  311.96034026145935\n"
     ]
    }
   ],
   "source": [
    "tables = [\n",
    "#     (\"coreapi_namebasics\", \"name_basics.tsv\", namebasics, 2),\n",
    "    (\"coreapi_titlebasics\", \"title_basics.tsv\", titlebasics, 10),\n",
    "#     (\"coreapi_titleakas\", \"title_akas.tsv\", titleakas, 9)\n",
    "#     (\"coreapi_link\", \"links_final.tsv\", 3),\n",
    "#     (\"coreapi_titlerating\", \"title_ratings.tsv\", 4),\n",
    "#     (\"coreapi_titleprincipals\", \"title_principals.tsv\", 7)\n",
    "         ]\n",
    "for table in tables:\n",
    "    insert_table(*table)\n",
    "    cur.execute(\"PRAGMA wal_checkpoint\")\n",
    "# insert_crew()\n",
    "cur.execute(\"PRAGMA wal_checkpoint\")\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
