{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "colab_type": "code",
    "id": "W386wG42sjjI",
    "outputId": "5185660a-9d39-4162-8a70-fe0663f60c36"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nwj_7xZ3C7CL",
    "outputId": "55aa53b3-2021-4469-d15f-ea495920a2be"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "DqCUEfKEaUDv",
    "outputId": "9bbbc816-3269-4790-9596-b095928e39ba"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hnl2l1r-_uvv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "sess=tf.compat.v1.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ate-_ryEt4fL"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "downloaded = drive.CreateFile({'id':'1vmDB7CBUMF2gGH2D_EuSDmSaCiJxDJv6'}) \n",
    "downloaded.GetContentFile('ratings.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DeKnbcmsduI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pik8mQaPr8-w"
   },
   "outputs": [],
   "source": [
    "directory_name = ''\n",
    "filename = os.path.join(directory_name, 'ratings.csv')\n",
    "dataset = pd.read_csv(filename, sep=',')\n",
    "\n",
    "X_Data = np.asanyarray(dataset.sort_values(['userId', 'timestamp']).groupby('userId')['timestamp'].apply(list))\n",
    "X_data = dataset.sort_values(['userId', 'timestamp']).groupby('userId')['movieId'].apply(list)\n",
    "X_data = tf.keras.preprocessing.sequence.pad_sequences(X_data)\n",
    "\n",
    "l = []\n",
    "for i in range(1, len(X_data)):\n",
    "    l1 = []\n",
    "    for e in X_data[i]:\n",
    "        l1.append(str(e))\n",
    "    l.append(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kjHZQ53ZAa_y",
    "outputId": "3c8a2a3c-8df7-40ee-ac3c-c531f8f51c48"
   },
   "outputs": [],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uKfwdigtq_qd"
   },
   "outputs": [],
   "source": [
    "word_model = Word2Vec(l, size=100, min_count=1, window=5, iter=10)\n",
    "word_model.save('word2vec.model')\n",
    "# noinspection PyTypeChecker\n",
    "max_sentence_len = len(max(l, key=len))\n",
    "\n",
    "\n",
    "def word2idx(word_):\n",
    "    return word_model.wv.vocab[word_].index\n",
    "\n",
    "\n",
    "def idx2word(idx):\n",
    "    return word_model.wv.index2word[idx]\n",
    "\n",
    "\n",
    "train_x = np.zeros([len(l), max_sentence_len, 100], dtype=np.float32)\n",
    "train_y = np.zeros([len(l), 100], dtype=np.float32)\n",
    "for i, sentence in enumerate(l):\n",
    "    for t, word in enumerate(sentence[:-1]):\n",
    "        train_x[i, t] = word_model[word]\n",
    "    train_y[i] = word_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VllmZ2uGtUZT"
   },
   "outputs": [],
   "source": [
    "class ReverseEmbedding(tf.keras.layers.Layer):\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        dot_product = tf.matmul(\n",
    "            tf.nn.l2_normalize(W, axis=1),\n",
    "            tf.nn.l2_normalize(inputs, axis=1),\n",
    "            transpose_b=True)\n",
    "        dot_product = W.dot(inputs, normalize=True)\n",
    "        return tf.argmax(dot_product,axis=0)\n",
    "\n",
    "class CustomLoss(tf.keras.losses.CosineSimilarity):\n",
    "    \n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "        return super(self, W(y_true), W(y_pred))\n",
    "\n",
    "vocab_size=100\n",
    "vector_size=30\n",
    "max_val = 1023\n",
    "max_sentence_len = len(max(l, key=len))\n",
    "model = tf.keras.Sequential()\n",
    "W = tf.keras.layers.Embedding(max_val+1, vector_size, mask_zero=True, name='W')\n",
    "model.add(W)\n",
    "model.add(tf.keras.layers.LSTM(128))\n",
    "model.add(tf.keras.layers.Dense(max_val, activation='linear'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "# loss = CustomLoss()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "print(model.summary())\n",
    "import numpy as np\n",
    "x_train = np.random.randint(max_val, size=(7097,3014))\n",
    "y_train = np.random.randint(max_val, size=(7097,1))\n",
    "history = model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(history.history['loss']).plot(logy=True)\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Train Error\")\n",
    "\n",
    "model_save_path = os.path.join(directory_name, 'keras_model.h5')\n",
    "model.save(model_save_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
